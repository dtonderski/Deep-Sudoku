{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ad0133-6d07-45cf-9788-1562698560d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet git+https://github.com/dtonderski/DeepSudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe16c3a-393a-40ff-bebf-69d313e53509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: deepsudoku\n",
      "Version: 0.8.4\n",
      "Summary: Solving Sudokus using a Neural Network assisted Monte-Carlo approach.\n",
      "Home-page: https://github.com/dtonderski/DeepSudoku\n",
      "Author: davton\n",
      "Author-email: dtonderski@gmail.com\n",
      "License: GNU GPLv3\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: einops, numpy, py-sudoku, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show deepsudoku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631761c3-2c35-446f-9d3d-62d6ced59634",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data\n",
    "Starting from solved sudoku, first split the data into train/val/test, then load it into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df4942-56aa-4192-85f7-13d37d2efa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepsudoku as ds\n",
    "from deepsudoku.utils import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825a518d-b2a7-432e-92ae-53912475820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sudokus_raw, val_sudokus_raw, _ = data_utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6857eba3-f909-4242-ad27-37db2be376c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sudokus = data_utils.make_moves(val_sudokus_raw, n_moves_distribution=data_utils.uniform_possible_moves_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b331b7-ae60-451e-88fd-b0a95c5daee5",
   "metadata": {},
   "source": [
    "### Network\n",
    "Load and configure the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9de9cf-51f0-429e-9482-0653837ea953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsudoku.dsnn import se_resnet, loss\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ffcec5-8d6f-41ef-a224-fd8edb6208e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = se_resnet.SeResNet(blocks = 10, filters = 128, se_channels = 32, dropout = 0.2).cuda()\n",
    "optimizer = torch.optim.Adam(network.parameters())\n",
    "loss_fn = loss.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7933be-e00e-4cc0-b0ce-a50590e8e391",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training\n",
    "The training loop consists of first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e31358-a04c-42ca-83e8-63630c9828a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsudoku.dsnn.training import generate_training_data\n",
    "from deepsudoku.dsnn.evaluation import evaluate, get_averages, print_evaluation, categorical_accuracy, binary_accuracy\n",
    "from deepsudoku.utils import network_utils\n",
    "from deepsudoku.montecarlo.simulation import get_n_simulations_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cb4af2-501a-4004-acb7-13ad1d511892",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations_function = get_n_simulations_function(1, 64, use_builtin_difficulty=False)\n",
    "min_data_size = 16384\n",
    "sudokus_to_evaluate = 128\n",
    "generate_and_evaluate_every_n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4551974e-cfc2-4ce3-8148-d89a6c6490a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(previous_data)=12\n"
     ]
    }
   ],
   "source": [
    "previous_data = []\n",
    "previous_simulations_to_save = 15\n",
    "\n",
    "previous_data_path = '../models/initial/previous_data.pkl'\n",
    "\n",
    "if os.path.exists(previous_data_path):\n",
    "    with open(previous_data_path, 'rb') as f:\n",
    "        previous_data = pkl.load(f)\n",
    "    current_train_sudokus = [sudoku for simulation_sudokus in previous_data for sudoku in simulation_sudokus]\n",
    "print(f\"{len(previous_data)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16aedafa-2c72-4122-b00c-e78f050f41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e07fb65-149b-4fea-a284-edc9d3b900de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "best_model_path = f'../models/initial/best.pth'\n",
    "if os.path.exists(best_model_path):\n",
    "    print(\"Loading model\")\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    network.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    losses = checkpoint['losses']\n",
    "    cat_accs = checkpoint['cat_accs']\n",
    "    bin_accs = checkpoint['bin_accs']\n",
    "    min_percentages = checkpoint['min_percentages']\n",
    "else:\n",
    "    losses = []\n",
    "    cat_accs = []\n",
    "    bin_accs = []\n",
    "    min_percentages = []\n",
    "    \n",
    "starting_epoch = len(losses)\n",
    "best_percentage = 0 if len(min_percentages) == 0 else min_percentages[-1]\n",
    "print(f\"{starting_epoch=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1655e7d-412d-4fa4-88ed-2852e5a8de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc54c95f-9d9e-4751-9396-e42d036d1abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/128, time = 2022-12-13 06:29:20.146159\n",
      "17/128, time = 2022-12-13 06:29:28.849171\n",
      "33/128, time = 2022-12-13 06:29:38.211088\n",
      "49/128, time = 2022-12-13 06:29:54.252297\n",
      "65/128, time = 2022-12-13 06:30:04.670692\n",
      "81/128, time = 2022-12-13 06:30:20.131395\n",
      "97/128, time = 2022-12-13 06:30:24.223491\n",
      "113/128, time = 2022-12-13 06:30:34.054361\n",
      "0 to 9 zeros: average moves before ending: 5.9, avg percentage completed: 100.0\n",
      "10 to 19 zeros: average moves before ending: 15.0, avg percentage completed: 100.0\n",
      "20 to 29 zeros: average moves before ending: 24.3, avg percentage completed: 99.8\n",
      "30 to 39 zeros: average moves before ending: 35.3, avg percentage completed: 100.0\n",
      "40 to 49 zeros: average moves before ending: 44.2, avg percentage completed: 100.0\n",
      "50 to 59 zeros: average moves before ending: 45.1, avg percentage completed: 84.4\n",
      "60 to 69 zeros: average moves before ending: 26.9, avg percentage completed: 43.7\n",
      "Sampled 0/16384 sudokus, time = 2022-12-13 06:30:43.556594\n",
      "Sampled 2055/16384 sudokus, time = 2022-12-13 06:31:16.839738\n",
      "Sampled 4266/16384 sudokus, time = 2022-12-13 06:32:31.483902\n",
      "Sampled 6369/16384 sudokus, time = 2022-12-13 06:33:15.260252\n",
      "Sampled 8271/16384 sudokus, time = 2022-12-13 06:34:06.654350\n",
      "Sampled 10244/16384 sudokus, time = 2022-12-13 06:34:32.310723\n",
      "Sampled 12296/16384 sudokus, time = 2022-12-13 06:35:14.961195\n",
      "Sampled 14492/16384 sudokus, time = 2022-12-13 06:36:02.924057\n",
      "Sampled 16496/16384 sudokus, time = 2022-12-13 06:36:30.823059\n",
      "Valids fraction: 0.76, sampled from 85 sudokus\n",
      "len(current_train_sudokus)=214191, current_fraction=0.5076030272046912.\n",
      "========================================================================\n",
      "Current fraction exceeded 0.5, stop training!\n",
      "========================================================================\n",
      "Min percentage increased from 0.27396680600673196 to 0.4365436109222465! Saving network\n",
      "Epoch 100, batch 20480/214191,batch_p_loss.item()=0.7840, batch_v_loss.item()=0.5097, batch_cat_acc=0.6472, batch_bin_acc=0.7329\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     60\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m network(x)\n\u001B[1;32m     62\u001B[0m binary_cross_entropy_weights \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mget_binary_cross_entropy_weights(y[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39many(torch\u001B[38;5;241m.\u001B[39misnan(binary_cross_entropy_weights)):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAAAAAAAAAAAAAAAAAAAA!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     65\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m100\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train = True\n",
    "\n",
    "if train:\n",
    "    for epoch in range(starting_epoch, epochs):\n",
    "        if epoch % generate_and_evaluate_every_n_epochs == 0:\n",
    "            network.eval()\n",
    "            moves_before_failure_dict, percentage_completed_dict = evaluate(val_sudokus, network, n_simulations_function, \n",
    "                                                                            n_played_sudokus = sudokus_to_evaluate)\n",
    "\n",
    "            avg_moves_dict, avg_percentage_dict = get_averages(moves_before_failure_dict, percentage_completed_dict)\n",
    "\n",
    "            print_evaluation(avg_moves_dict, avg_percentage_dict)\n",
    "            \n",
    "            current_min_average_percentage_before_failure = min(avg_percentage_dict.values())\n",
    "            min_percentages.append(current_min_average_percentage_before_failure)\n",
    "\n",
    "            train_sudokus = data_utils.make_moves(train_sudokus_raw, n_moves_distribution=data_utils.difficulty_uniform_combo_distribution)\n",
    "            generated_train_sudokus = generate_training_data(train_sudokus, network, n_simulations_function, verbose = 1, min_data_size = min_data_size)\n",
    "            \n",
    "            previous_data.append(generated_train_sudokus)\n",
    "            if len(previous_data) > previous_simulations_to_save:\n",
    "                del previous_data[0]\n",
    "            \n",
    "            with open(previous_data_path, 'wb') as f:\n",
    "                pkl.dump(previous_data, f)\n",
    "            \n",
    "            current_train_sudokus = [sudoku for simulation_sudokus in previous_data for sudoku in simulation_sudokus]\n",
    "            current_fraction = sum([x[2] for x in current_train_sudokus])/len([x[2] for x in current_train_sudokus])\n",
    "            print(f\"{len(current_train_sudokus)=}, {current_fraction=}.\")\n",
    "            \n",
    "            if (current_fraction > 0.5):\n",
    "                print(\"========================================================================\")\n",
    "                print(\"Current fraction exceeded 0.5, stop training!\")\n",
    "                print(\"========================================================================\")\n",
    "                break\n",
    "\n",
    "            \n",
    "            network.train()\n",
    "            \n",
    "            if current_min_average_percentage_before_failure > best_percentage:\n",
    "                print(f\"Min percentage increased from {best_percentage} to \"\n",
    "                      f\"{current_min_average_percentage_before_failure}! Saving network\")\n",
    "                best_percentage = current_min_average_percentage_before_failure\n",
    "                torch.save({\n",
    "                    'model_state_dict': network.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'cat_accs': cat_accs,\n",
    "                    'bin_accs': bin_accs,\n",
    "                    'losses': losses,\n",
    "                    'min_percentages': min_percentages\n",
    "                    }, f'{best_model_path}')\n",
    "            \n",
    "        random.shuffle(current_train_sudokus)\n",
    "        batch_losses, batch_cat_accs, batch_cat_accs_weights, batch_bin_accs = [], [], [], []\n",
    "        \n",
    "        for i in range(0, len(current_train_sudokus), batch_size):\n",
    "            batch_sudokus = current_train_sudokus[i:i+batch_size]\n",
    "\n",
    "            x_np, y_np = data_utils.generate_numpy_batch(batch_sudokus, augment = True)\n",
    "            x, y = network_utils.numpy_batch_to_pytorch(x_np, y_np, 'cuda')\n",
    "            y_pred = network(x)\n",
    "            \n",
    "            binary_cross_entropy_weights = loss.get_binary_cross_entropy_weights(y[1])\n",
    "\n",
    "            batch_p_loss, batch_v_loss = loss_fn(x, y_pred, y, binary_cross_entropy_weights=binary_cross_entropy_weights)    \n",
    "            batch_loss = batch_v_loss + batch_p_loss\n",
    "\n",
    "            batch_cat_acc = categorical_accuracy(x, y, y_pred)\n",
    "            \n",
    "            # Weight is number of valid sudokus\n",
    "            batch_cat_accs_weights.append(y[1].sum())\n",
    "            \n",
    "            batch_bin_acc = binary_accuracy(y, y_pred)\n",
    "\n",
    "            batch_losses.append(batch_loss.item())\n",
    "            batch_cat_accs.append(batch_cat_acc)\n",
    "            batch_bin_accs.append(batch_bin_acc)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch}, batch {min(i+batch_size, len(current_train_sudokus))}/{len(current_train_sudokus)},\" \n",
    "                  f\"{batch_p_loss.item()=:.4f}, {batch_v_loss.item()=:.4f}, {batch_cat_acc=:.4f}, {batch_bin_acc=:.4f}\", end = \"\\r\")\n",
    "\n",
    "        losses.append(sum(batch_losses)/len(batch_losses))\n",
    "        batch_cat_accs_weights = [x/sum(batch_cat_accs_weights) for x in batch_cat_accs_weights]\n",
    "        # Weighted average over cat_accs\n",
    "        cat_accs.append(sum([x*y for x,y in zip(batch_cat_accs, batch_cat_accs_weights)]))\n",
    "        bin_accs.append(sum(batch_bin_accs)/len(batch_bin_accs))\n",
    "\n",
    "        print(f'Epoch {epoch}, loss = {losses[-1]:.4f}, cat_acc = {cat_accs[-1]:.4f}, bin_acc = {bin_accs[-1]:.4f}, time = {datetime.now()}.                                       ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d978762-7ed8-4775-bd40-d3420b6eab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
